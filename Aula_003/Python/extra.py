import google.generativeai as genai
from google.api_core.exceptions import InvalidArgument
import os
import gradio as gr
import time
from home_ass_rev import set_light_state, start_music

GEMINI_API_KEY = os.environ["GEMINI_API_KEY"]

genai.configure(api_key=GEMINI_API_KEY)
initial_prompt = (
    "Voc√™ √© um assistente virtual que pode controlar dispositivos dom√©sticos. "
    "Voc√™ tem acesso a fun√ß√µes que controlam a casa da pessoa que est√° usando."
    "Chame as fun√ß√µes quando achar que deve, mas nunca exponha o c√≥digo delas."
    "Assuma que a pessoa √© amig√°vel e ajude-a a entender o que aconteceu "
    "se algo der errado ou se voc√™ precisar de mais informa√ß√µes."
    "N√£o esque√ßa de, de fato, chamar as fun√ß√µes."
)
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    tools=[set_light_state, start_music],
    system_instruction=initial_prompt,
)

chat = model.start_chat(enable_automatic_function_calling=True)


def assemble_prompt(message):
    prompt = [message["text"]]
    uploaded_files = upload_file(message)
    # prompt.extend(uploaded_files)

    return prompt


def upload_file(message):
    responseFiles = []

    if message["files"]:
        for file in message["files"]:
            uploaded_file = genai.upload_file(file["path"])
            while uploaded_file.state.name == "PROCESSING":
                time.sleep(3)
                uploaded_file = genai.upload_file(uploaded_file.name)
            responseFiles.append(uploaded_file)

    return responseFiles


def gradio_chat(message, _history):
    prompt = assemble_prompt(message)

    try:
        response = chat.send_message(prompt)
    except InvalidArgument as e:
        response = chat.send_message(
            f"O usu√°rio te enviou um arquivo para voc√™ ler e obteve erro: {e}."
            "Pode explicar o que houve e dizer quais tipos de arquivos voc√™ "
            "d√° suporte? Assuma que a pessoa n√£o sabe programa√ß√£o e "
            "n√£o quer o erro original. Explique de forma simples e concisa."
        )

    return response.text


chat_interface = gr.ChatInterface(
    fn=gradio_chat, title="Assistente Inteligente üè†", multimodal=True
)

chat_interface.launch()
